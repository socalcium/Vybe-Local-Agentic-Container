# Vybe AI Assistant Environment Configuration
# Copy this file to .env and modify as needed

# Application Settings
FLASK_DEBUG=False
VYBE_TEST_MODE=False

# Server Configuration
HOST=127.0.0.1
PORT=8000

# HTTPS Configuration
ENABLE_HTTPS=True
FORCE_HTTPS=False
# SSL_CERT_PATH=/path/to/certificate.crt
# SSL_KEY_PATH=/path/to/private.key

# Security - Use a secure, randomly generated key for production.
SECRET_KEY="2m4vUUBJ&ypVHDW31NlQhDP!QNDGdW0jmSotBX@ykZIfRBLTa0&ufANPGh9w*^*W"

# LLM Backend Configuration (using llama-cpp-python)
LLM_SERVER_HOST="127.0.0.1"
LLM_SERVER_PORT=11435
LLM_SERVER_TIMEOUT=30
LLM_MODEL_PATH=""  # Path to GGUF model file, blank for auto-detection

# File Upload Limits
MAX_FILE_SIZE=16777216
MAX_CONTENT_LENGTH=16777216

# RAG Configuration
RAG_CHUNK_SIZE=500
RAG_CHUNK_OVERLAP=50
RAG_VECTOR_DB_PATH="./rag_data/chroma_db"
RAG_KNOWLEDGE_BASE_PATH="./rag_data/knowledge_base"

# Logging
LOG_LEVEL=INFO

# Database Configuration
# DATABASE_URI=sqlite:///site.db